\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}


\makeatletter


\providecommand{\tabularnewline}{\\}


\makeatother

\chapter{Modeling}

\section{Introduction}
%introduce actual fit, fit regions, systematics treatment, results of fit stages
The modeling for this analysis uses the standard counting experiment approach with a Poisson likelihood. The MC model is data driven such that background composes most of the regions and tunes the data and MC agreement. This agreement translates into well constrained background predictions in sensitive regions with sparse background with an ABCD-like approach. To achieve a robust fit model three stages of fits are performed, one with the Control Region (CR) which has no signal presence, a Validation Region (VR) which is a partially unblinded region with mild sensitivity designed to validate the CR model and demonstrate reasonable modeling in regions untouched by the CR , and finally SR which is comprised of the high $R_{ISR}$ bins which are sensitive to all signal regions. Following the full fit, limits can be calculated which test the hypotheses of background only model versus background plus signal model. 


\section{Fit Strategy and Fit Region Definitions}
%CR VR SR
The strategy for developing a robust fit model with the ability to accurately predict the background in the most sensistive regions is carried out in three stages. The stages combine different regions with varying sensitivity, they are the Control Region, Validation Region, and Signal Region. The control region guaranteed to have no signal sensitivity and also covers nearly a majority of all bins. Quantitatively, the expected contamination in the control region from any signal process being stops,sleptons, or electroweakinos is $<1\%$ in and below sparticle masses that are of potential discovery interest. Signals can appear in the CR, especially stops, due to the strong cross-section, but, the mass ranges that can appear at the few percent level or more have already been well excluded by other searches. The categories and bins that compose the CR are easily described as simply the low $R_{ISR}$ region and more specifically the lowest two $R_{ISR}$ bins of almost every category. The only category that has been specifically excluded from the CR is 2L high $p_T^{ISR}$ categories which were especially sensitive to some stop signals and borderline sensitive to electroweakinos. The CR region is then fully described 1298 total bins, of which, hold $42\%$ of total expected Run II events. This means that the CR will ultimately dominate the behavior of the fit, but, it does not guarantee everywhere will be well modeled e.g. high $R_{ISR}$. To deal with this short coming, we introduce a complementary region the Validation Region. This region is designed to extend the control region to sample all types of categories and kinematics. The VR unmasks all the bronze categories, so it is composed the remaining bronze category $R_{ISR}$ not covered by the CR. Fitting the CR+VR is a conservative approach unblinding useful in validating the fit model everywhere. The signal presence in VR bins is mild where stops and electroweakinos can show up in the most sensitive categories, like $\mu\mu$, at the few percent level. Together the CR+VR fit covers 1517 total bins with an increase in the expected number of events $10\%$. The remaining region is the signal region SR, it comprises  1576 total bins, and a smaller fraction of $19\%$ of total expected events. The sensitivity to every signal is high in this region examples of the S/B significance using the Zbinomial statistic if Fig X.

\FigTwoScale{Model_figs/0L_4J_ratioZbin_highDm_RISR_Mperp.pdf}{Model_figs/1L_G_0J_ratioZbin_chargeSep_RISR_Mperp.pdf}{Distributions that show the relative sensitivity of compressed stop processes in each of $R_{ISR}$ and $M_\perp$ bins. The left distribution shows 0 lepton and 4 S-jets with color-coded b-tag counting categories. The $k^+$ denotes high $p_T^{ISR}$ and high $\gamma_\perp$ categories. The right distribution shows 1 gold lepton and 0 S-jets with color-coded lepton flavor categories. The X in both distribution indicates the integration over all sub-categories not explicitly listed.}{fig:zbi1}{0.8}{0.8}

\FigTwoScale{Model_figs/zbi_2lgold.png}{Model_figs/zbi_2lbron.png}{A comparison of three different signal processes in a 2 lepton selection for bins of $R_{ISR}$ and $M_\perp$. The left plot shows gold regions with 0 S-jets which are split by sign or include SVs. The right plot shows bronze regions with 1 S-jet split by flavor combinations. The Bronze categories are still able to be sensitive in high $R_{ISR}$ despite being considered background rich regions. The X in both distributions indicates integration of all categories not shown.}{fig:zbi2}{0.8}{0.8}




\section{Fit Implementation and Model Defintion}
%Poisson likelihood
The fitting framework is provided by the HiggsCombine tool which generates datacards that encodes all the components of the fit into a standard format that is processed by CombineHarvester and RooFit/RooStats packages \cite{Antcheva:2009zz}\cite{moneta2011roostats}. The fit and its components can be represented by a Poisson likelihood defined as:
\begin{equation}
\label{eq:fit}
\mathcal{L}(\vec{\alpha}|\vec{x}) = \bigg[ \prod_i^N \text{Pois}(x_i|\lambda_i(\vec{\alpha})) \bigg] \bigg[\prod_j^M \pi_j(\alpha_j) \bigg]
\end{equation}
The contents of equation \ref{eq:fit} extend over the range of all $N$ analysis bins where each $i$-th bin is composed of a count of observed events $x_i$ and expected events $\lambda_i$. The expected events are subject to the set of nuisance parameters $\vec{\alpha}$ of which some are conditioned by prior probability distributions $\pi_j(\alpha_j)$. The ideal model for $\lambda(\vec{\alpha})$ is found by maximizing the likelihood \ref{eq:fit} with the minimum set of nuisance parameters $\vec{\alpha}$ by fitting the stages of fit regions such that the model is sensitive to signals and the signal + background hyptothesis.  There are three types of nuisances implemented in the fit, freely floating rate parameters, log-normal constrained parameters, and shape parameters.  Freely floating paramters contribute to a factor $\kappa$, with a starting value of 1,  that is applied to the expected bin yield $\lambda$ to adjust the bin yield by some fraction with respect to the nominal value. The free parameters have no associated penalty with their adjustment and are fully determined by data. Individual bins $i$ are mapped together by common processes $k$ which are all associated under a common nuisance $j$. The selection of processes associated to a nuisance parameter can either be the contribution from a background process or associated flavor separated fake leptons which are also split by source: heavy flavor(HF) or light flavor(LF) . The definition of a free rate parameter can then be defined as 
\begin{equation}
\label{eq:rateparam}
\kappa_{ijk}(\alpha_j) = \alpha_j
\end{equation}  
The log-normal parameters also functions of a $\kappa$ factor that is applied to an expected events of the associated bin. The log-normal parameter is different from the freely floating paramters in such that it is penalized for moving from the nominal value with based on normally distributed prior $\pi(\alpha_j)$. Along with a prior associated uncertainty on a process $j$ of nuisance $k$, that is $\sigma_{jk}$, the log-normal factors are defined as
\begin{equation}
\label{eq:logparam}
\kappa_{ijk}(\alpha_j) = (1+\sigma_{ijk})^{\alpha_j}
\end{equation}

The third type of nuisance is different from the first two such that it does not associate with and modify the process components for a particular bin, instead, the shape nuisances adjust expected bin yields based on the underlying shapes of the $R_{ISR}$ and $M_\perp$ distributions. The $kappa$ factor for a bin yield is then a function of up and down variations of one of the kinematic variables which are also encoded with a normally distributed prior $\pi(\alpha_j)$. The $\kappa$ definition is based on the interpolation $-1<\alpha_j<1$ and is written as follwing based on a predefined shape treatment \cite{Conway:2011in}
\begin{equation}
\label{eq:shapeparam}
\kappa_{ijk}(\alpha_j)= 1 + \frac{1}{2}((\delta^+ - \delta^-)\alpha_j + \frac{1}{8}(\delta^+ + \delta^-)(3\alpha_j^6-10\alpha_j^4+15\alpha_j^2))
\end{equation}
the $\delta^\pm$ components are ratios of the up and down shape variations, $\lambda^{up/down}$, to the nominal shape< $\lambda^{nominal}$ such that $\delta^+ = \lambda^{up}/\lambda^{nominal}$ and $\delta^- = \lambda^{down}/\lambda^{nominal}.$

From the Likelihood Equation \ref{eq:fit} which is composed of the three types of nuisances from equations \ref{eq:rateparam}, \ref{eq:logparam}, \ref{eq:shapeparam}. These nuisances are mapped to either a set of processes or shapes and also mapped to a set of associated bins. The product of the three $\kappa$ factors multiply the nominal expectation $\lambda$ such that they maximize the likelihood and in turn the agreement between the observed data $\vec{x}$ and $\vec{\lambda}$. 


\section{Definitions of Modeling Systematics}
The set of nuisances that based on the types described in the previous section went through an extensive evolution beginning with very early fits with only 10 nuisances in \cite{erich thesis}. This fit only used a single nuisance to describe b-tag systematics, one for MET trigger systematics, one for luminosity and one for each background process rate. The final configuration consists of over 200 nuisances which can be divided into 5 subcategories: kinematic, process normalizations, lepton fakes, lepton categorization, and b-tagging. The optimizations of these nuisances, that is, their bin association and process mapping along with their allowed degrees of freedom has undergone extensive study. The complete list of systematics, their type, and prior uncertainties are listed in Tables \ref{tab:kinnuisance}, \ref{tab:btagnuisance}, \ref{tab:lcatnuisance}, \ref{tab:procnuisance}, \ref{tab:fakenuisance}, \ref{tab:svnuisance}, and \ref{tab:othernuisance}.  The kinematic nuisances from Table \ref{tab:kinnuisance} contribute 27 factors which serve the purpose accounting for systematic effects between the high and low $p_T^{ISR}$ and $\gamma_\perp$ for each lepton and jet multiplicity. The kinematic nuisances, and nuisances in general, that appear to be missing e.g. $\gamma_\perp$ 0L 1J are merged with neighboring jet multiplicites if they are determined to be extraneous degrees of freedom or are highly correlated with another nuisance. Table \ref{tab:btagnuisance} describes 73 nuisances which are designed to accomodate systematic effects from categorization of b-tagged jets in either the S or ISR system in each lepton and jet multiplicity. Regions with few b-tags or are dominated by a single process include the contributions from all background processes, otherwise, each factor is split into two where one is associated with tt+jets only and the other is associated with the combined background of everything else. There are 21 lepton categorization nuisances which are designed to account for systematically different rates in Gold categories versus Silver or Bronze categories. Table \ref{tab:procnuisance} shows the rates for each background process, which includes a special hierarchy parameterization that will be discussed later. The rule of thumb for background process rates is that dominant processes are split by lepton and jet multilpicity, intermediate backgrounds are split by lepton, and rare backgrounds are mapped globally with a single nuisance. The fake lepton nuisances are comprised of global rates for each flavor and source, a single nuisance to account for the global rate of  charge misidentification, and the fake shapes. The fake shapes are split by flavor, lepton multiplicity, and jet multiplicity, originally they were also split by source but this introduced many extraneous parameters where HF and LF were highly correlated. The fake shapes target systematic effects from the shapes of either $R_{ISR}$, $M_\perp$ and are based on $1\sigma$ up and down variations which are applied to the shape templates in Equation \ref{eq:shapeparam}. The last two tables \ref{tab:svnuisance} and \ref{tab:othernuisance} account for systematics from SV effiency or binning rapidity which is either central, $\eta^c$, or forward, $\eta^f$ as well as other sources of systematics.

% table of systematics
\begin{table}
\centering
\caption{Kinematic nuisances mappings which are applied to the higher of the two available bins. Bracketed jet mappings indicate all integer jet multiplicities between the listed inclusive edges. All factors are assigned a $20\%$ prior uncertainty.}
\begin{tabular}{ccc}
\hline 
Category Mapping & $N_L$ Mapping & $N_{jets}^S$  Mapping \\ 
\hline 
\hline
$p_T^{ISR}$  & 0 & $[1,\geq5]$ \\ 
$p_T^{ISR}$ & 1 & $[0,\geq4]$ \\ 
$p_T^{ISR}$ (QCD) & 0 & $[0,\geq5]$ \\ 
$\gamma_\perp$ & 0 & $[2,\geq4]$ \\ 
$\gamma_\perp$ & 1 & $[1,\geq4]$ \\ 
$\gamma_\perp$ & 2 & $[0,\geq2]$ \\  
$\gamma_\perp$ (QCD) & 0 & $[2,\geq4]$ \\ 
\hline 
\end{tabular} 
\label{tab:kinnuisance}
\end{table}


\begingroup

\begin{table}
\centering
\caption{The log-normal nuisance mapping for all b-tag counting categories. Includes all combinations of Process $\times$ Category $\times$ $(N_\ell,N_{jet}^S)$ multiplicities. All factors are assigned a prior $20\%$ uncertainty.}
\setlength{\tabcolsep}{10pt} % Default value: 6pt
\renewcommand{\arraystretch}{1.5} % Default value:
\begin{tabular}{lc}

\multicolumn{2}{|l}{Process Mapping per $(N_\ell,N_{jet}^S)$ } \\ 
\hline 
 & (Combined/All) or ($tt+jets$) or (not $tt+jets$)  \\ 
\multicolumn{2}{|l}{Category Mapping per $(N_\ell,N_{jet}^S)$ } \\ 
\hline 
 & $(N_{b-tag}^{ISR},N_{b-tag}^S)=\{(0,1),(1,0),(1,1),( \text{inclusive} ,\geq2) \}$ \\ 
\multicolumn{2}{|l}{Combined/All Nuisances}  \\ 
\hline 
 & $(N_\ell,N_{jet}^S)=\{(0,1),(1,1),(2,1),(2,2) \}$ \\ 

\end{tabular} 
\label{tab:btagnuisance}
\end{table}
\endgroup

\begin{table}
\centering
\caption{Lepton category nuisance mapping. The complete set of nuisances is represented by the product of the $N_\ell \times N_{jet}^S$ with an assigned prior uncertainty or $20\%$. The category !Gold indicates the combined Silver and Bronze categories. }
\begin{tabular}{cc|ccc}

 &  & \multicolumn{3}{c}{$N_\ell$ Mapping} \\  
 &  & 1$\ell$ & 2$\ell$ & 3$\ell$ \\ 
\hline 
\multirow{6}{*}{
\rotatebox[origin=c]{90}{$N_{jet}^S$ Mapping}}  & Inclusive &  & \makecell{$(ee,\mu\mu,e\mu)\times$!Gold \\ \quad } & \makecell{$(Z*,noZ*) $ \\ \quad } \\ 
 
 & 0J & $(e,\mu)\times$(Gold,!Gold) & \makecell{$(OS,SS)\times$ Gold \\ $(\ell\ell)\times$(Gold,!Gold) \\ \quad } &   \\ 
 
 & 1J & $\ell$ Gold & $(Z*,noZ*)\times$ Gold &  \\ 
 
 & 2J & $\ell$ Gold & $(Z*,noZ*)\times$ Gold &  \\ 
 
 & 3J & $\ell$ Gold &  &  \\ 
 
 & 4J & $\ell$ Gold &  &  \\ 

\end{tabular} 
\label{tab:lcatnuisance}

\end{table}


\begin{table}
\centering
\caption{The nuisance mapping split by lepton and jet multiplicity for background processes. The dominant backgrounds W+jets and tt+jets are implented with a hierarchy parameterization of factors.  Global factors indicate mapping to every bin and $N_{jet}^S$ implies each possible number of jets for a given lepton multiplicity.}
 
\begin{tabular}{ccc}
\hline 
Category Mapping & Process Mapping & Param. Details \\ 
\hline 
\hline
per  $(N_\ell =1,2,3  \, ,N_{jet}^S)$ & W+jets & hierarchy \\ 

per $(N_\ell = 0 \, , N_{jet}^S)$ & (W+jets)+(ZDY) & hierarchy \\ 

per $(N_\ell, N_{jet}^S)$ & tt+jets & hierarchy \\ 
 
per $(N_\ell=0,1,2 \,, N_{jet}^S)$ & QCD & $0\ell$ floating otherwise $20\%$ prior \\ 
per $N_\ell=1,2,3$ & (ZDY)+(DB) & $20\%$ prior \\ 
per $N_\ell=0,1,2$ & ST & $20\%$ prior \\ 
global & TB & $20\%$ prior \\ 
global & ZDY & free floating \\ 
global & DB & free floating \\ 
\hline 
\end{tabular} 
\label{tab:procnuisance}

\end{table}

\begin{table}
\centering
\caption{The nuisances associated to fake leptons. The global or silver or bronze rates are split between MC matched source of either Heavy flavor or Light flavor. The shape systematics are applied per lepton and S-jet combinations but combine HF/LF sources and split by flavor only.}
\begin{tabular}{ccc}

Category Mapping & Process Mapping & Parameter Details \\ 
\hline 
\hline
$\ell^\pm\ell^\pm$ & Global & Free floating \\ 
 
Global & $(e,\mu)\times(HF,LF)$ & Free floating \\ 
 
Silver & $(e,\mu)\times(HF,LF)$ & $20\%$ prior \\ 
 
Bronze & $(e,\mu)\times(HF,LF)$ & $20\%$ prior \\ 
 
per $(N_\ell^S,N_{jet}^S)$ & $(e,\mu)\times(R_{ISR}^{shape}, M_\perp^{shape})$ & $5\%$ prior \\ 
\hline 
\end{tabular} 
\label{tab:fakenuisance}

\end{table}


\begin{table}
\centering
\caption{The set of nuisances associated to the categories that involve tagged SVs. The SV counting rates are mapped globally to every bin and the kinematic $\eta$ separation is split between SVs associated with tt+jets versus SVs associated with anything else.}
\begin{tabular}{cc}
Category mapping & process mapping \\ 
\hline 
\hline
$N_{SV}^S=1$ & All \\ 
 
$N_{SV}^S \geq 1$ & All \\ 
 
$|\eta_{SV}^f|$ & tt+jets \\ 
 
$|\eta_{SV}^f|$ & other \\ 
\hline 
\end{tabular} 
\label{tab:svnuisance}

\end{table}

\begin{table}
\centering
\caption{Additional secondary systematics which account for various scale factors or systematic effects of jet reconstruction and clustering.  The nuisances with a (*) are not currently implemented but will be added in later in the final model. }
\begin{tabular}{|c|c|}
\hline 
Systematic Source and Scale Factors & Parameter Type \\ 
\hline 
Luminosity & log-normal \\  
$e,\mu$ Efficiency & log-normal \\ 
b-tag efficiency & log-normal \\ 
*Factorization, Renormalization, PDF, and $Q^2$ & log-normal \\ 
*JES \& type-I MET & shape \\ 
*Unclustered Energy & shape \\ 
MET Trigger Efficiency & shape \\ 
Lepton FastSIM SF & log-normal \\ 
SV FastSIM SF & log-normal \\ 
b-jet FastSim SF & log-normal \\ 
*MET FastSIm Correction & shape \\ 
\hline 
\end{tabular} 
\label{tab:othernuisance}

\end{table}

%begin hierarchy
The background process hierarchy hinted at from Table \ref{tab:procnuisance} is a special parameterization of nuisance parameters organized into a hierarchy which is implemented separately for the two dominant backgrounds W+jets and tt+jets. At the top of these process hierarchies is the root factor  associated with the region with the highest statisical power and purity for that process. This factor, for a particular lepton and S jet multiplicity, informs neighboring jet multiplicity factors and in turn those neighbors then inform their neighbors. This allows for the root parameters for each process to be interpreted as an estimate of a singular normalization scale factor for that group of processes, while also allowing for independent factors in different categories that are interpreted and constrained relative to the higher factor. 

For example: The root factor for W+jets is 1L 0J, chosen because it is $14\%$ of the total process yield and $93\%$ of the total background for that particular region. 0L 2J, 1L 1J, and 1L 2J have comparable stats with up to $20\%$ more events in 1L 1J but with a loss of at least $20\%$ in terms of purity or the W+jets proportion to other backgrounds. The $\theta^{Wjets}_{1L, 0J}$ ``root" scale factor maps to every analysis bin for the W+jets process and governs the overall rate. This means that the root factor is multiplied against every other scale factor in each lepton multiplicity. An example "low level" parameter would be $\theta^{Wjets}_{1L, 4J}$, which is multiplied by $\theta^{Wjets}_{1L, 0J}\theta^{Wjets}_{1L, 1J}\theta^{Wjets}_{1L ,2J}\theta^{Wjets}_{1L, 3J}$ whenever it is applied to a process, which means the rate reported for this parameter is relative to each preceding nuisance at a higher level in the hierarchy.  A similar hierarchial parameterization is evaluated for tt+jets, and both hierarchy trees are shown in Figure \ref{fig:hierarchytree}. The 0L hierarchy for W+jets is special, due to very high correlations with the ZDY process from the similarities between $W$ and Z$\nu\nu$ decays. Here, the process mapping combines the backgrounds ZDY and W+jets while the ZDY,DB factor for 0L has been removed. s.
%hier diagrams
\FigTwoScale{Model_figs/wjets_hierarchy.png}{Model_figs/ttbar_hierarchy.png}{Pair of k-nary trees that illustrate the hierarchical organization of background rates for W+jets and tt+jets.}{fig:hier}{0.49}{0.49}
%end hierarchy

\section{Development of Modeling Systematics}


The optimization of each group of systematics was conducted over CR fits to 2016 data and then expanded to include multiple years then account for systematic effects induced from different run conditions. The statistical evaluation of each fit is performed by comparing metrics such as the $\log\mathcal{L}$, $\chi^2$, significance of the residuals of each bin (pull distributions), and impacts distributions which are a series of separate fits that independently vary all of the nuisance parameters to assess the impact of each on the POI. Multiple definitions of pulls are used together the main one being $ (O-E)/(E+\sigma_{postfit})$ where the $O$ is the observed data, $E$ is the expected events post-fit, the denonimator is also the expected post-fit events under the assumption that each bin is poisson distributed. The total error of the denominator is then the sum in quadrature of the poisson variance and the post fit variance for the bin in question. Similar pull defintions assist this one such as the same evaulation withough post-fit variance or the pull evaluated with respect to the pre-fit values. Each fit evaluation is performed on subsets of the same fit which includes all bins, each individual lepton multiplicity, or gold silver or bronze. The statisical errors for each bin are assumed to be gaussian with sufficient number of events. In the case of bins with very few events they assumed to be poisson distributed, this is important distinction when combining different bins, which can vary in numbers of events by orders of magnitude, into a pull distribution. For instance if a deviation of a few observed events were to occur in a bin with only a few expected events, the pull or z-score, would be significantly large which shows that the gaussian assumption in the z-score is inaccurate. To correct this assumption, each bin is given the ``Poisson treatment" new z-score is calculated from the poisson probality of the original observation given the expectation. The recipe for calculating the adjusted z-scores is as follows
\begin{itemize}
\item[1.] Generate N trials, each with new expectation $E_i' \sim \mathcal{N}(E,1)$
\item[2.] Generate new observations $O_i'\sim \text{Poisson}(E_i')$
\item[3.] Count $k$ successes such that $O',E'$ follow the original observation $(O<E \,\, \text{or} \, \, O>E)$
\item[4.] Compute Poisson probability $P=k/N$ 
\item[5.] Translate P into a z-score with normal distribution quantile
\item[6.] Compute error on z-score with up/down variations of binomial error
\item[7.] Sign z-score based on $O-E$ convention
\end{itemize} 

The consequence of the poisson treatment is that the z-score significance is reduced in low statistics cases where $O>E$ and increased in cases with $O<E$ this is due to the asymmetery in the poisson distribution with a long tail tending to higher values. Example pull distributions that compare the early fit model with the most complete model are shown in Figure Z. Comparisons of the same complete model with and withouth the poisson treatment is shown. The progression of the fit model's likelihood and the impact of the different groups of nuisances is summarized Figure Z with accompanied Table T with brief descriptions of the evolution of each fit configuration. 
 
%build 62 no poisson vs build 62 w/ poisson
\FigTwoScale{Model_figs/build62_pull_run2_nopoisson.pdf}{Model_figs/build62_pull_run2_poisson.pdf}{Comparison of Run II CR fits with Build 62 of \ref{tab:builds} without Poisson treatment (left) and with Poisson treatment (right). The improvement by implementing is the Poisson treatment shown in the RMS and fitted $\sigma$ of the right distribution by reducing the number of large outliers due to bins with low statistics. }{fig:comparePoissonPull}{0.49}{0.49}
 
%build 8 pull with last 16 build no poisson\
\FigTwoScale{Model_figs/build8_pull_2016.pdf}{Model_figs/build62_pull_2016.pdf}{A comparison of the Poisson corrected builds from \ref{tab:builds} with the first Build 8 on the left and the final Build 62 on the right. Both distributions use only 2016 data and MC scaled to 138 fb$^{-1}$. }{fig:compareBuildPull}{0.49}{0.49}



%plot of likelihoods
\FigOneScale{Model_figs/likelihood_progress.pdf}{The progression of the CR fit log likelihood following the model version milestones listed in the Build Table \ref{tab:builds}.}{fig:likes}{0.6}

%table of builds
\begin{table}
\caption{Listing of all the model verison milestones with a brief description of each build, its Id number and number of nuisances. }
\begin{tabular}{ll}
\hline 
Build 8 & N Nuisances = 186 \\ 
\hline
 & \makecell[l]{Used 3 shape sytematics for W+jets, QCD, Fakes. All other backgrounds \\ are grouped together under ``other'' and split by $(N_\ell^S,N_{jet}^S)$} \\ 
 & \\
\hline 
Build 17 & N Nuisances = 179 \\
\hline
 &\makecell[l]{Removed W+jets and QCD shapes due to over fitting. Added in W+jets \\ hierarchy.  Split up ``other'' into 3 groups \{(tt+jets, ST),(ZDY),(DB,TB)\}\\ each split by $(N_\ell^S,N_{jet}^S)$} \\
 & \\
\hline
Build 23 & N Nuisances = 193 \\
\hline
 & \makecell[l]{Added a simplified b-tag configuration with a splitting by $(N_{b-tag}^S,N_{b-tag}^{ISR})$\\ and further split by $(N_\ell^S,N_{jet}^S)$ }\\
 & \\ 
\hline
Build 24 & N Nuisances = 194 \\
\hline
 & \makecell[l]{Added a nuisance to adjust the rate of same-sign lepton pairs.}  \\
 & \\
\hline
Build 25 & N Nuisances = 194 \\
\hline
 & \makecell[l]{Added tt+jets hierarchy. Reconfigured background process grouping to \\ \{(ZDY, DB),(ST,TB)\} with full $(N_\ell^S,N_{jet}^S)$ splitting } \\
 & \\
\hline
Build 30 & N Nuisances = 229 \\
\hline
 & \makecell[l]{Implemented lepton category nuisances from Table \ref{tab:lcatnuisance} and the Bronze \\ and Silver global fake rates from Table \ref{tab:fakenuisance} } \\
 & \\
\hline
Build 37 & N Nuisances = 209 \\
\hline
 & \makecell[l]{Reworked background process grouping to the final configuration in Table \\ \ref{tab:procnuisance}  and consolidated extraneous degrees of freedom. \\Consolidated Fake shapes to no longer split between HF and LF. } \\
 & \\
\hline 
Build 62 & N Nuisances = 227 \\
\hline
 & \makecell[l]{Reworked b-tagging parameters to include process splitting from Table \ref{tab:btagnuisance}. \\ This build reflects the final configuration of all previously described nuisances \\ and those implemented from Table \ref{tab:othernuisance}. } \\
\end{tabular} 
\label{tab:builds}
\end{table}
\section{Control Region Fit Results}
The results of the control region fit and the control region plus validation region fit using the fit model described in the previous section lead to excellent agreement between data and MC. IDistributions which summarize the effects of the various nuisances, each have simplified categorization with splitting over a targeted category and integrated over sub categories, are shown in Figures X and Y. The first Figure X, shows a summary of the data and MC agreement for each lepton multiplicity, this demonstrates the benefit of the jet multiplicity splitting, and also the effect of kinematic factors in 2L and 3L. The following figure Figure Y shows splitting by ptisr, gamT, and btagging. Some of the selected post-fit nuisance factors for the same fit are shown in Figures Z and P. These show that the nuisances are both necessary and effective in improving data to MC agreement.

%0L jet split plot
%1L 2L 3L
\FigFour{Model_figs/0L_S_Summary.pdf}{Model_figs/1L_J_Summary_fakesIncl_b-fit.pdf}{Model_figs/2L_GSBJ_b-fit.pdf}{Model_figs/3L_Summary_fakesIncl_b-fit}{CR post-fit summary plots split by number of S-jets for each lepton  multiplicity. The bottom two figures for 2 lepton and 3 lepton selections include both jet or quality and jet or lepton category respectively. The two included types of splitting in 2 and 3 lepton are not mutually exclusive.}{fig:crsummary}

\FigTwoScale{Model_figs/1L_G_0J_ChargeSep_fakesIncl_b-fit.pdf}{Model_figs/0L_3J_PTISRgamT_fakesIncl_b-fit.pdf}{CR post-fit summary plots with the category associated with the root factor of W+jets (left) and a 0 lepton selection splitting by kinematic categories $p_T^{ISR}$ and $\gamma_\perp$ (right).}{fig:crprockin}{0.49}{0.49}

\FigTwoScale{Model_figs/2L_Cat_Summary.pdf}{Model_figs/2L_B_2J_DefaultPlot_b-fit}{CR post-fit summary plots demonstrating the effects on 2 leptons which are split by lepton categories (left) or a Bronze only region which is strongly associated with lepton fake factors (right).}{fig:cr2lsummary}{0.49}{0.49}

\FigTwoScale{Model_figs/1L_G_4J_DefaultPlot_fakesIncl_b-fit.pdf}{Model_figs/SV_Summary.pdf}{CR post-fit summary examples which show the agreement of data to the fitted background model for b-tagging and SV categories.}{fig:crbtagsummary}{0.49}{0.49}


In addition to the control region only fit, a control region combined with the validation region fit was performed. This fit uses the final systematic configuration but excludes the fake shapse. Fake shapes are excluded due to the implementation requiring consisting binning across gold, silver, and bronze. In the case of the appended validation region there are more bronze bins, because the cover the entire $R_{ISR}$ range, than silver or gold bins. This CR+VR fit result is reasonable but has apparent systematic mismodeling from the removal of fake shapes.  To accomodate this a bronze only fit is performed. This fit includes only the bronze regions for each lepton multiplicity and includes the complete set of systematics. Example results are shown in Figure X which show excellent modeling in high $R_{ISR}$ regions.

%bronze only fit
\FigTwo{Model_figs/1L_B_0J_b-fit.pdf}{Model_figs/2L_B_2J_b-fit.pdf}{The Bronze only category fit with fake dominated 1 lepton and 2 lepton bronze categories.}{fig:crvrsummary}
\section{Bias tests}

One possible danger of having two many degrees in the fit model is that the model would be too flexible and fit away potential signal. To test for this we perform and ensemble of pseudeoexperiments with and without signal injection to test if the fit model recovers the correct hypothesis.  If the fit is unbiased and sensitive to various signals then the signal strenth parameter or POI should be evaluated as $r=0$ in the case of no signal injection and $r=1$ when signal is injected.  These hypothesis are tested by generating observed data in each bin centered on the MC expectation, the MC is fit to data and the POI is extracted. This pseudo experiment was performed with a handful of points around the edge of the mass asymptotic limits for T2tt, TChiWZ, and TSlepSlep. The results are shown in Figure \ref{fig:biasstudy} where we see no bias in the fit, and the recovery of the correct hypothesis. Overall this means that the final configuration of nuisances does not fit away potential signal and is sensitive to discovery.

\FigThreeScale{Model_figs/T2tt_7500670_r0_r1.pdf}{Model_figs/TChiWZ_3250315_r0_r1.pdf}{Model_figs/TSlepSlep_2500245_r0_r1.pdf}{Signal injection and bias test for three different signal grid points. The top left is T2tt with $m_{\tilde{t}}=750$ and $m_{\tilde{\chi}_1^0}=670$. The top right is TChiWZ with $m_{\tilde{\chi}_2^0}=325$ and $m_{\tilde{\chi}_1^0}=315$. The bottom figure uses TSlepSlep with $m_{\tilde{\ell}}=250$ and $m_{\tilde{\chi}_1^0}=245$ \textit{Source R. Salvatico} \cite{AN}}{fig:biasstudy}{0.49}{0.49}{0.49}
 


